{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "otherwise-cruise",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.10344828]\n",
      " [0.64367816]\n",
      " [0.04597701]\n",
      " ...\n",
      " [0.52873563]\n",
      " [0.31034483]\n",
      " [0.11494253]]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from random import randint\n",
    "from sklearn.utils import shuffle\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "#sample creation\n",
    "\n",
    "train_labels = []\n",
    "train_samples = []\n",
    "\n",
    "for i in range(50):\n",
    "    random_younger = randint(13, 64)\n",
    "    train_samples.append(random_younger)\n",
    "    train_labels.append(1)\n",
    "\n",
    "    random_older = randint(65, 100)\n",
    "    train_samples.append(random_older)\n",
    "    train_labels.append(0)\n",
    "\n",
    "for i in range(1000):\n",
    "    random_younger = randint(13, 64)\n",
    "    train_samples.append(random_younger)\n",
    "    train_labels.append(0)\n",
    "\n",
    "    random_older = randint(65, 100)\n",
    "    train_samples.append(random_older)\n",
    "    train_labels.append(1)\n",
    "\n",
    "train_labels = np.array(train_labels)\n",
    "train_samples = np.array(train_samples)\n",
    "train_labels, train_samples = shuffle(train_labels, train_samples)\n",
    "\n",
    "scaler = MinMaxScaler(feature_range=(0,1))\n",
    "scaled_train_samples = scaler.fit_transform(train_samples.reshape(-1, 1))\n",
    "\n",
    "print(scaled_train_samples)\n",
    "\n",
    "###"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "analyzed-adult",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30\n",
      "189/189 - 1s - loss: 0.6375 - accuracy: 0.5545 - val_loss: 0.6279 - val_accuracy: 0.6000\n",
      "Epoch 2/30\n",
      "189/189 - 0s - loss: 0.6132 - accuracy: 0.6460 - val_loss: 0.5951 - val_accuracy: 0.7143\n",
      "Epoch 3/30\n",
      "189/189 - 0s - loss: 0.5782 - accuracy: 0.7201 - val_loss: 0.5596 - val_accuracy: 0.7667\n",
      "Epoch 4/30\n",
      "189/189 - 0s - loss: 0.5433 - accuracy: 0.7683 - val_loss: 0.5233 - val_accuracy: 0.8143\n",
      "Epoch 5/30\n",
      "189/189 - 0s - loss: 0.5070 - accuracy: 0.8085 - val_loss: 0.4837 - val_accuracy: 0.8381\n",
      "Epoch 6/30\n",
      "189/189 - 0s - loss: 0.4684 - accuracy: 0.8503 - val_loss: 0.4489 - val_accuracy: 0.8667\n",
      "Epoch 7/30\n",
      "189/189 - 0s - loss: 0.4362 - accuracy: 0.8656 - val_loss: 0.4192 - val_accuracy: 0.8667\n",
      "Epoch 8/30\n",
      "189/189 - 0s - loss: 0.4074 - accuracy: 0.8799 - val_loss: 0.3931 - val_accuracy: 0.8905\n",
      "Epoch 9/30\n",
      "189/189 - 0s - loss: 0.3823 - accuracy: 0.8884 - val_loss: 0.3715 - val_accuracy: 0.9000\n",
      "Epoch 10/30\n",
      "189/189 - 0s - loss: 0.3602 - accuracy: 0.9005 - val_loss: 0.3539 - val_accuracy: 0.9095\n",
      "Epoch 11/30\n",
      "189/189 - 0s - loss: 0.3424 - accuracy: 0.9106 - val_loss: 0.3379 - val_accuracy: 0.9143\n",
      "Epoch 12/30\n",
      "189/189 - 0s - loss: 0.3268 - accuracy: 0.9143 - val_loss: 0.3255 - val_accuracy: 0.9143\n",
      "Epoch 13/30\n",
      "189/189 - 0s - loss: 0.3143 - accuracy: 0.9180 - val_loss: 0.3160 - val_accuracy: 0.9095\n",
      "Epoch 14/30\n",
      "189/189 - 0s - loss: 0.3035 - accuracy: 0.9228 - val_loss: 0.3074 - val_accuracy: 0.9095\n",
      "Epoch 15/30\n",
      "189/189 - 0s - loss: 0.2949 - accuracy: 0.9217 - val_loss: 0.3016 - val_accuracy: 0.9143\n",
      "Epoch 16/30\n",
      "189/189 - 0s - loss: 0.2875 - accuracy: 0.9233 - val_loss: 0.2961 - val_accuracy: 0.9143\n",
      "Epoch 17/30\n",
      "189/189 - 0s - loss: 0.2811 - accuracy: 0.9238 - val_loss: 0.2924 - val_accuracy: 0.9143\n",
      "Epoch 18/30\n",
      "189/189 - 0s - loss: 0.2757 - accuracy: 0.9280 - val_loss: 0.2885 - val_accuracy: 0.9143\n",
      "Epoch 19/30\n",
      "189/189 - 0s - loss: 0.2713 - accuracy: 0.9254 - val_loss: 0.2855 - val_accuracy: 0.9143\n",
      "Epoch 20/30\n",
      "189/189 - 0s - loss: 0.2675 - accuracy: 0.9254 - val_loss: 0.2848 - val_accuracy: 0.9238\n",
      "Epoch 21/30\n",
      "189/189 - 0s - loss: 0.2641 - accuracy: 0.9280 - val_loss: 0.2844 - val_accuracy: 0.9381\n",
      "Epoch 22/30\n",
      "189/189 - 0s - loss: 0.2616 - accuracy: 0.9370 - val_loss: 0.2804 - val_accuracy: 0.9238\n",
      "Epoch 23/30\n",
      "189/189 - 0s - loss: 0.2591 - accuracy: 0.9307 - val_loss: 0.2789 - val_accuracy: 0.9238\n",
      "Epoch 24/30\n",
      "189/189 - 0s - loss: 0.2568 - accuracy: 0.9296 - val_loss: 0.2792 - val_accuracy: 0.9238\n",
      "Epoch 25/30\n",
      "189/189 - 0s - loss: 0.2553 - accuracy: 0.9354 - val_loss: 0.2769 - val_accuracy: 0.9238\n",
      "Epoch 26/30\n",
      "189/189 - 0s - loss: 0.2535 - accuracy: 0.9317 - val_loss: 0.2765 - val_accuracy: 0.9238\n",
      "Epoch 27/30\n",
      "189/189 - 0s - loss: 0.2521 - accuracy: 0.9339 - val_loss: 0.2752 - val_accuracy: 0.9238\n",
      "Epoch 28/30\n",
      "189/189 - 0s - loss: 0.2509 - accuracy: 0.9317 - val_loss: 0.2752 - val_accuracy: 0.9238\n",
      "Epoch 29/30\n",
      "189/189 - 0s - loss: 0.2497 - accuracy: 0.9386 - val_loss: 0.2739 - val_accuracy: 0.9238\n",
      "Epoch 30/30\n",
      "189/189 - 0s - loss: 0.2487 - accuracy: 0.9312 - val_loss: 0.2741 - val_accuracy: 0.9238\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x19753998340>"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Activation, Dense\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.metrics import categorical_crossentropy\n",
    "\n",
    "#Building the model\n",
    "model = Sequential([\n",
    "    Dense(units = 16, input_shape = (1,), activation = 'relu'),\n",
    "    Dense(units= 32, activation = 'relu'), #relu = max(0, a). Alternatives are sigmoid and softmax functions!\n",
    "    Dense(units = 2, activation = 'softmax') #final output layer giving probabilities of the output\n",
    "])\n",
    "\n",
    "model.compile(optimizer=Adam(learning_rate=0.0001), loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
    "#model.fit(x=scaled_train_samples, y=train_labels, batch_size=10, epochs=30, shuffle=True, verbose=2) #verbose tells level of output\n",
    "model.fit(x=scaled_train_samples, y=train_labels, validation_split=0.1, batch_size=10, epochs=30, shuffle=True, verbose=2) #with a vaildation set\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "quick-honey",
   "metadata": {},
   "outputs": [],
   "source": [
    "#making test set\n",
    "\n",
    "test_labels = []\n",
    "test_samples = []\n",
    "\n",
    "for i in range(10):\n",
    "    random_younger = randint(13, 64)\n",
    "    test_samples.append(random_younger)\n",
    "    test_labels.append(1)\n",
    "\n",
    "    random_older = randint(65, 100)\n",
    "    test_samples.append(random_older)\n",
    "    test_labels.append(0)\n",
    "\n",
    "for i in range(200):\n",
    "    random_younger = randint(13, 64)\n",
    "    test_samples.append(random_younger)\n",
    "    test_labels.append(0)\n",
    "\n",
    "    random_older = randint(65, 100)\n",
    "    test_samples.append(random_older)\n",
    "    test_labels.append(1)\n",
    "\n",
    "test_labels = np.array(test_labels)\n",
    "test_samples = np.array(test_samples)\n",
    "test_labels, test_samples = shuffle(test_labels, test_samples)\n",
    "\n",
    "scaled_test_samples = scaler.fit_transform(test_samples.reshape(-1, 1))\n",
    "###"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "spectacular-dance",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.9793452  0.02065476]\n",
      " [0.9786078  0.02139219]\n",
      " [0.07299537 0.9270047 ]\n",
      " [0.97621834 0.02378169]\n",
      " [0.9787754  0.02122467]\n",
      " [0.9324081  0.06759194]\n",
      " [0.49057642 0.50942355]\n",
      " [0.97783864 0.02216138]\n",
      " [0.0528025  0.94719744]\n",
      " [0.33827186 0.6617281 ]\n",
      " [0.978231   0.021769  ]\n",
      " [0.03115033 0.9688496 ]\n",
      " [0.77362835 0.22637159]\n",
      " [0.02230924 0.97769076]\n",
      " [0.07809337 0.9219066 ]\n",
      " [0.9791709  0.02082916]\n",
      " [0.9791709  0.02082916]\n",
      " [0.9401724  0.05982767]\n",
      " [0.8983361  0.10166382]\n",
      " [0.21344028 0.7865597 ]\n",
      " [0.03556701 0.96443295]\n",
      " [0.9779537  0.02204627]\n",
      " [0.01950561 0.9804944 ]\n",
      " [0.03556701 0.96443295]\n",
      " [0.9623559  0.03764416]\n",
      " [0.95266944 0.04733051]\n",
      " [0.01950561 0.9804944 ]\n",
      " [0.92264813 0.07735185]\n",
      " [0.9786405  0.02135949]\n",
      " [0.04334794 0.95665205]\n",
      " [0.02550539 0.9744946 ]\n",
      " [0.97411966 0.02588041]\n",
      " [0.02086139 0.9791387 ]\n",
      " [0.03115033 0.9688496 ]\n",
      " [0.97704244 0.02295759]\n",
      " [0.12590982 0.8740902 ]\n",
      " [0.06845681 0.9315432 ]\n",
      " [0.9401724  0.05982767]\n",
      " [0.8983361  0.10166382]\n",
      " [0.97704244 0.02295759]\n",
      " [0.27137482 0.7286252 ]\n",
      " [0.03556701 0.96443295]\n",
      " [0.80015135 0.19984868]\n",
      " [0.21344028 0.7865597 ]\n",
      " [0.979301   0.02069897]\n",
      " [0.16507185 0.8349281 ]\n",
      " [0.45114982 0.5488501 ]\n",
      " [0.8460425  0.15395743]\n",
      " [0.9401724  0.05982767]\n",
      " [0.9786405  0.02135949]\n",
      " [0.607611   0.392389  ]\n",
      " [0.80015135 0.19984868]\n",
      " [0.9787754  0.02122467]\n",
      " [0.03115033 0.9688496 ]\n",
      " [0.8460425  0.15395743]\n",
      " [0.9779537  0.02204627]\n",
      " [0.03556701 0.96443295]\n",
      " [0.979301   0.02069897]\n",
      " [0.0528025  0.94719744]\n",
      " [0.9793452  0.02065476]\n",
      " [0.06845681 0.9315432 ]\n",
      " [0.0528025  0.94719744]\n",
      " [0.04945248 0.9505476 ]\n",
      " [0.12590982 0.8740902 ]\n",
      " [0.9798139  0.02018613]\n",
      " [0.8829375  0.11706249]\n",
      " [0.12590982 0.8740902 ]\n",
      " [0.97903985 0.02096015]\n",
      " [0.9791709  0.02082916]\n",
      " [0.6446507  0.3553493 ]\n",
      " [0.03799591 0.96200407]\n",
      " [0.01950561 0.9804944 ]\n",
      " [0.10949168 0.8905083 ]\n",
      " [0.9780928  0.02190721]\n",
      " [0.9779537  0.02204627]\n",
      " [0.14439069 0.85560924]\n",
      " [0.0950925  0.90490746]\n",
      " [0.10949168 0.8905083 ]\n",
      " [0.12590982 0.8740902 ]\n",
      " [0.12590982 0.8740902 ]\n",
      " [0.6800353  0.31996468]\n",
      " [0.6446507  0.3553493 ]\n",
      " [0.03799591 0.96200407]\n",
      " [0.07809337 0.9219066 ]\n",
      " [0.0528025  0.94719744]\n",
      " [0.02230924 0.97769076]\n",
      " [0.03799591 0.96200407]\n",
      " [0.27137482 0.7286252 ]\n",
      " [0.9623559  0.03764416]\n",
      " [0.01950561 0.9804944 ]\n",
      " [0.9786078  0.02139219]\n",
      " [0.9401724  0.05982767]\n",
      " [0.08427152 0.9157285 ]\n",
      " [0.06845681 0.9315432 ]\n",
      " [0.03328802 0.96671194]\n",
      " [0.77362835 0.22637159]\n",
      " [0.9785049  0.02149515]\n",
      " [0.9785049  0.02149515]\n",
      " [0.9798139  0.02018613]\n",
      " [0.9578345  0.04216551]\n",
      " [0.97411966 0.02588041]\n",
      " [0.97987455 0.02012547]\n",
      " [0.9752703  0.02472966]\n",
      " [0.97208965 0.02791027]\n",
      " [0.07299537 0.9270047 ]\n",
      " [0.06418084 0.93581915]\n",
      " [0.03799591 0.96200407]\n",
      " [0.02086139 0.9791387 ]\n",
      " [0.03556701 0.96443295]\n",
      " [0.33827186 0.6617281 ]\n",
      " [0.04945248 0.9505476 ]\n",
      " [0.6446507  0.3553493 ]\n",
      " [0.03115033 0.9688496 ]\n",
      " [0.9401724  0.05982767]\n",
      " [0.97411966 0.02588041]\n",
      " [0.97903985 0.02096015]\n",
      " [0.0272666  0.97273344]\n",
      " [0.04334794 0.95665205]\n",
      " [0.9623559  0.03764416]\n",
      " [0.9401724  0.05982767]\n",
      " [0.0601548  0.9398452 ]\n",
      " [0.97903985 0.02096015]\n",
      " [0.9791709  0.02082916]\n",
      " [0.9623559  0.03764416]\n",
      " [0.03115033 0.9688496 ]\n",
      " [0.16507185 0.8349281 ]\n",
      " [0.07809337 0.9219066 ]\n",
      " [0.97411966 0.02588041]\n",
      " [0.979864   0.02013604]\n",
      " [0.45114982 0.5488501 ]\n",
      " [0.9786078  0.02139219]\n",
      " [0.24122326 0.7587768 ]\n",
      " [0.07299537 0.9270047 ]\n",
      " [0.3745658  0.62543416]\n",
      " [0.04334794 0.95665205]\n",
      " [0.5301204  0.46987966]\n",
      " [0.03115033 0.9688496 ]\n",
      " [0.30378637 0.6962136 ]\n",
      " [0.8829375  0.11706249]\n",
      " [0.8983361  0.10166382]\n",
      " [0.979301   0.02069897]\n",
      " [0.9785049  0.02149515]\n",
      " [0.02550539 0.9744946 ]\n",
      " [0.33827186 0.6617281 ]\n",
      " [0.9798139  0.02018613]\n",
      " [0.08427152 0.9157285 ]\n",
      " [0.03799591 0.96200407]\n",
      " [0.9752703  0.02472966]\n",
      " [0.18806422 0.8119358 ]\n",
      " [0.02086139 0.9791387 ]\n",
      " [0.97704244 0.02295759]\n",
      " [0.9796438  0.0203561 ]\n",
      " [0.06845681 0.9315432 ]\n",
      " [0.97987455 0.02012547]\n",
      " [0.16507185 0.8349281 ]\n",
      " [0.12590982 0.8740902 ]\n",
      " [0.04334794 0.95665205]\n",
      " [0.05636603 0.943634  ]\n",
      " [0.5301204  0.46987966]\n",
      " [0.07299537 0.9270047 ]\n",
      " [0.03328802 0.96671194]\n",
      " [0.03799591 0.96200407]\n",
      " [0.02086139 0.9791387 ]\n",
      " [0.9578345  0.04216551]\n",
      " [0.97783864 0.02216138]\n",
      " [0.97987455 0.02012547]\n",
      " [0.0272666  0.97273344]\n",
      " [0.03115033 0.9688496 ]\n",
      " [0.9798139  0.02018613]\n",
      " [0.02550539 0.9744946 ]\n",
      " [0.04630458 0.9536955 ]\n",
      " [0.979864   0.02013604]\n",
      " [0.8829375  0.11706249]\n",
      " [0.02914577 0.9708543 ]\n",
      " [0.77362835 0.22637159]\n",
      " [0.0272666  0.97273344]\n",
      " [0.10949168 0.8905083 ]\n",
      " [0.45114982 0.5488501 ]\n",
      " [0.74470854 0.2552914 ]\n",
      " [0.97903985 0.02096015]\n",
      " [0.9786078  0.02139219]\n",
      " [0.9401724  0.05982767]\n",
      " [0.24122326 0.7587768 ]\n",
      " [0.9787754  0.02122467]\n",
      " [0.18806422 0.8119358 ]\n",
      " [0.02550539 0.9744946 ]\n",
      " [0.04630458 0.9536955 ]\n",
      " [0.5692898  0.43071017]\n",
      " [0.02385515 0.97614485]\n",
      " [0.97890806 0.02109195]\n",
      " [0.03115033 0.9688496 ]\n",
      " [0.04945248 0.9505476 ]\n",
      " [0.21344028 0.7865597 ]\n",
      " [0.45114982 0.5488501 ]\n",
      " [0.27137482 0.7286252 ]\n",
      " [0.97903985 0.02096015]\n",
      " [0.08427152 0.9157285 ]\n",
      " [0.0528025  0.94719744]\n",
      " [0.04334794 0.95665205]\n",
      " [0.08427152 0.9157285 ]\n",
      " [0.33827186 0.6617281 ]\n",
      " [0.77362835 0.22637159]\n",
      " [0.5692898  0.43071017]\n",
      " [0.16507185 0.8349281 ]\n",
      " [0.3745658  0.62543416]\n",
      " [0.03799591 0.96200407]\n",
      " [0.05636603 0.943634  ]\n",
      " [0.02550539 0.9744946 ]\n",
      " [0.0528025  0.94719744]\n",
      " [0.9663431  0.0336569 ]\n",
      " [0.607611   0.392389  ]\n",
      " [0.74470854 0.2552914 ]\n",
      " [0.9779537  0.02204627]\n",
      " [0.03556701 0.96443295]\n",
      " [0.01950561 0.9804944 ]\n",
      " [0.9796438  0.0203561 ]\n",
      " [0.97783864 0.02216138]\n",
      " [0.04058368 0.95941633]\n",
      " [0.97783864 0.02216138]\n",
      " [0.16507185 0.8349281 ]\n",
      " [0.8829375  0.11706249]\n",
      " [0.9786405  0.02135949]\n",
      " [0.9786078  0.02139219]\n",
      " [0.8460425  0.15395743]\n",
      " [0.05636603 0.943634  ]\n",
      " [0.97943044 0.02056957]\n",
      " [0.03115033 0.9688496 ]\n",
      " [0.97968686 0.02031316]\n",
      " [0.86555547 0.13444452]\n",
      " [0.08427152 0.9157285 ]\n",
      " [0.0272666  0.97273344]\n",
      " [0.27137482 0.7286252 ]\n",
      " [0.03328802 0.96671194]\n",
      " [0.33827186 0.6617281 ]\n",
      " [0.03115033 0.9688496 ]\n",
      " [0.10949168 0.8905083 ]\n",
      " [0.0950925  0.90490746]\n",
      " [0.02385515 0.97614485]\n",
      " [0.03799591 0.96200407]\n",
      " [0.80015135 0.19984868]\n",
      " [0.9752703  0.02472966]\n",
      " [0.04058368 0.95941633]\n",
      " [0.97208965 0.02791027]\n",
      " [0.06418084 0.93581915]\n",
      " [0.9779537  0.02204627]\n",
      " [0.0601548  0.9398452 ]\n",
      " [0.97943044 0.02056957]\n",
      " [0.9578345  0.04216551]\n",
      " [0.24122326 0.7587768 ]\n",
      " [0.21344028 0.7865597 ]\n",
      " [0.0601548  0.9398452 ]\n",
      " [0.24122326 0.7587768 ]\n",
      " [0.45114982 0.5488501 ]\n",
      " [0.3745658  0.62543416]\n",
      " [0.97704244 0.02295759]\n",
      " [0.03115033 0.9688496 ]\n",
      " [0.30378637 0.6962136 ]\n",
      " [0.9401724  0.05982767]\n",
      " [0.0528025  0.94719744]\n",
      " [0.97890806 0.02109195]\n",
      " [0.9779537  0.02204627]\n",
      " [0.96959955 0.03040039]\n",
      " [0.04630458 0.9536955 ]\n",
      " [0.9578345  0.04216551]\n",
      " [0.02086139 0.9791387 ]\n",
      " [0.03328802 0.96671194]\n",
      " [0.92264813 0.07735185]\n",
      " [0.9578345  0.04216551]\n",
      " [0.08427152 0.9157285 ]\n",
      " [0.06418084 0.93581915]\n",
      " [0.0601548  0.9398452 ]\n",
      " [0.02086139 0.9791387 ]\n",
      " [0.946766   0.05323403]\n",
      " [0.07809337 0.9219066 ]\n",
      " [0.946766   0.05323403]\n",
      " [0.02914577 0.9708543 ]\n",
      " [0.97890806 0.02109195]\n",
      " [0.978231   0.021769  ]\n",
      " [0.97890806 0.02109195]\n",
      " [0.02914577 0.9708543 ]\n",
      " [0.9796438  0.0203561 ]\n",
      " [0.97968686 0.02031316]\n",
      " [0.80015135 0.19984868]\n",
      " [0.97890806 0.02109195]\n",
      " [0.02230924 0.97769076]\n",
      " [0.0950925  0.90490746]\n",
      " [0.9780928  0.02190721]\n",
      " [0.10949168 0.8905083 ]\n",
      " [0.9578345  0.04216551]\n",
      " [0.0601548  0.9398452 ]\n",
      " [0.07299537 0.9270047 ]\n",
      " [0.14439069 0.85560924]\n",
      " [0.03556701 0.96443295]\n",
      " [0.5301204  0.46987966]\n",
      " [0.24122326 0.7587768 ]\n",
      " [0.95266944 0.04733051]\n",
      " [0.0272666  0.97273344]\n",
      " [0.9791709  0.02082916]\n",
      " [0.02385515 0.97614485]\n",
      " [0.9779537  0.02204627]\n",
      " [0.946766   0.05323403]\n",
      " [0.9401724  0.05982767]\n",
      " [0.06418084 0.93581915]\n",
      " [0.9786405  0.02135949]\n",
      " [0.02230924 0.97769076]\n",
      " [0.979864   0.02013604]\n",
      " [0.74470854 0.2552914 ]\n",
      " [0.9796438  0.0203561 ]\n",
      " [0.21344028 0.7865597 ]\n",
      " [0.30378637 0.6962136 ]\n",
      " [0.27137482 0.7286252 ]\n",
      " [0.02914577 0.9708543 ]\n",
      " [0.33827186 0.6617281 ]\n",
      " [0.9785049  0.02149515]\n",
      " [0.9401724  0.05982767]\n",
      " [0.97955894 0.02044098]\n",
      " [0.979864   0.02013604]\n",
      " [0.9783683  0.02163165]\n",
      " [0.04630458 0.9536955 ]\n",
      " [0.9783683  0.02163165]\n",
      " [0.16507185 0.8349281 ]\n",
      " [0.07299537 0.9270047 ]\n",
      " [0.02914577 0.9708543 ]\n",
      " [0.05636603 0.943634  ]\n",
      " [0.03328802 0.96671194]\n",
      " [0.9786078  0.02139219]\n",
      " [0.9785049  0.02149515]\n",
      " [0.95266944 0.04733051]\n",
      " [0.0528025  0.94719744]\n",
      " [0.9791709  0.02082916]\n",
      " [0.7134625  0.28653756]\n",
      " [0.41232753 0.58767253]\n",
      " [0.979864   0.02013604]\n",
      " [0.97903985 0.02096015]\n",
      " [0.97903985 0.02096015]\n",
      " [0.97411966 0.02588041]\n",
      " [0.05636603 0.943634  ]\n",
      " [0.01950561 0.9804944 ]\n",
      " [0.0950925  0.90490746]\n",
      " [0.30378637 0.6962136 ]\n",
      " [0.97903985 0.02096015]\n",
      " [0.14439069 0.85560924]\n",
      " [0.03328802 0.96671194]\n",
      " [0.41232753 0.58767253]\n",
      " [0.97704244 0.02295759]\n",
      " [0.12590982 0.8740902 ]\n",
      " [0.03328802 0.96671194]\n",
      " [0.95266944 0.04733051]\n",
      " [0.979864   0.02013604]\n",
      " [0.9779537  0.02204627]\n",
      " [0.9786078  0.02139219]\n",
      " [0.6800353  0.31996468]\n",
      " [0.01950561 0.9804944 ]\n",
      " [0.05636603 0.943634  ]\n",
      " [0.04630458 0.9536955 ]\n",
      " [0.01950561 0.9804944 ]\n",
      " [0.9783683  0.02163165]\n",
      " [0.9324081  0.06759194]\n",
      " [0.9785049  0.02149515]\n",
      " [0.03556701 0.96443295]\n",
      " [0.02550539 0.9744946 ]\n",
      " [0.45114982 0.5488501 ]\n",
      " [0.05636603 0.943634  ]\n",
      " [0.9786078  0.02139219]\n",
      " [0.8983361  0.10166382]\n",
      " [0.77362835 0.22637159]\n",
      " [0.03799591 0.96200407]\n",
      " [0.04058368 0.95941633]\n",
      " [0.97968686 0.02031316]\n",
      " [0.9401724  0.05982767]\n",
      " [0.86555547 0.13444452]\n",
      " [0.01950561 0.9804944 ]\n",
      " [0.978231   0.021769  ]\n",
      " [0.45114982 0.5488501 ]\n",
      " [0.97621834 0.02378169]\n",
      " [0.97955894 0.02044098]\n",
      " [0.9791709  0.02082916]\n",
      " [0.02550539 0.9744946 ]\n",
      " [0.80015135 0.19984868]\n",
      " [0.33827186 0.6617281 ]\n",
      " [0.96959955 0.03040039]\n",
      " [0.8829375  0.11706249]\n",
      " [0.02550539 0.9744946 ]\n",
      " [0.0272666  0.97273344]\n",
      " [0.97704244 0.02295759]\n",
      " [0.946766   0.05323403]\n",
      " [0.03328802 0.96671194]\n",
      " [0.18806422 0.8119358 ]\n",
      " [0.9663431  0.0336569 ]\n",
      " [0.04945248 0.9505476 ]\n",
      " [0.9401724  0.05982767]\n",
      " [0.9783683  0.02163165]\n",
      " [0.08427152 0.9157285 ]\n",
      " [0.97208965 0.02791027]\n",
      " [0.9793452  0.02065476]\n",
      " [0.02230924 0.97769076]\n",
      " [0.33827186 0.6617281 ]\n",
      " [0.02550539 0.9744946 ]\n",
      " [0.02385515 0.97614485]\n",
      " [0.27137482 0.7286252 ]\n",
      " [0.04334794 0.95665205]\n",
      " [0.9663431  0.0336569 ]\n",
      " [0.04058368 0.95941633]\n",
      " [0.9798139  0.02018613]\n",
      " [0.8242725  0.17572746]\n",
      " [0.9793452  0.02065476]\n",
      " [0.74470854 0.2552914 ]\n",
      " [0.97704244 0.02295759]\n",
      " [0.9787754  0.02122467]\n",
      " [0.9663431  0.0336569 ]\n",
      " [0.16507185 0.8349281 ]\n",
      " [0.9798139  0.02018613]\n",
      " [0.06845681 0.9315432 ]\n",
      " [0.97903985 0.02096015]\n",
      " [0.05636603 0.943634  ]\n",
      " [0.45114982 0.5488501 ]\n",
      " [0.9115055  0.08849451]\n",
      " [0.07299537 0.9270047 ]\n",
      " [0.9785049  0.02149515]\n",
      " [0.3745658  0.62543416]]\n"
     ]
    }
   ],
   "source": [
    "predictions = model.predict(x=scaled_test_samples, batch_size=10, verbose=0)\n",
    "print(predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "cardiac-automation",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0 0 1 0 0 0 1 0 1 1 0 1 0 1 1 0 0 0 0 1 1 0 1 1 0 0 1 0 0 1 1 0 1 1 0 1 1\n",
      " 0 0 0 1 1 0 1 0 1 1 0 0 0 0 0 0 1 0 0 1 0 1 0 1 1 1 1 0 0 1 0 0 0 1 1 1 0\n",
      " 0 1 1 1 1 1 0 0 1 1 1 1 1 1 0 1 0 0 1 1 1 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1\n",
      " 0 1 0 0 0 1 1 0 0 1 0 0 0 1 1 1 0 0 1 0 1 1 1 1 0 1 1 0 0 0 0 1 1 0 1 1 0\n",
      " 1 1 0 0 1 0 1 1 1 1 0 1 1 1 1 0 0 0 1 1 0 1 1 0 0 1 0 1 1 1 0 0 0 0 1 0 1\n",
      " 1 1 0 1 0 1 1 1 1 1 0 1 1 1 1 1 0 0 1 1 1 1 1 1 0 0 0 0 1 1 0 0 1 0 1 0 0\n",
      " 0 0 1 0 1 0 0 1 1 1 1 1 1 1 1 1 1 0 0 1 0 1 0 1 0 0 1 1 1 1 1 1 0 1 1 0 1\n",
      " 0 0 0 1 0 1 1 0 0 1 1 1 1 0 1 0 1 0 0 0 1 0 0 0 0 1 1 0 1 0 1 1 1 1 0 1 0\n",
      " 1 0 1 0 0 0 1 0 1 0 0 0 1 1 1 1 1 0 0 0 0 0 1 0 1 1 1 1 1 0 0 0 1 0 0 1 0\n",
      " 0 0 0 1 1 1 1 0 1 1 1 0 1 1 0 0 0 0 0 1 1 1 1 0 0 0 1 1 1 1 0 0 0 1 1 0 0\n",
      " 0 1 0 1 0 0 0 1 0 1 0 0 1 1 0 0 1 1 0 1 0 0 1 0 0 1 1 1 1 1 1 0 1 0 0 0 0\n",
      " 0 0 0 1 0 1 0 1 1 0 1 0 1]\n"
     ]
    }
   ],
   "source": [
    "rounded_predictions = np.argmax(predictions, axis = -1)\n",
    "print(rounded_predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "average-irish",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os.path\n",
    "if os.path.isfile('models/medical_trial_model.h5') is False:\n",
    "    model.save('models/medical_trial_model.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "younger-importance",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.models import load_model\n",
    "new_model = load_model('models/medical_trial_model.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "small-hobby",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_4\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_12 (Dense)             (None, 16)                32        \n",
      "_________________________________________________________________\n",
      "dense_13 (Dense)             (None, 32)                544       \n",
      "_________________________________________________________________\n",
      "dense_14 (Dense)             (None, 2)                 66        \n",
      "=================================================================\n",
      "Total params: 642\n",
      "Trainable params: 642\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "new_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "healthy-protest",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.9793452 , 0.02065476],\n",
       "       [0.9786078 , 0.02139219],\n",
       "       [0.07299537, 0.9270047 ],\n",
       "       [0.97621834, 0.02378169],\n",
       "       [0.9787754 , 0.02122467],\n",
       "       [0.9324081 , 0.06759194],\n",
       "       [0.49057642, 0.50942355],\n",
       "       [0.97783864, 0.02216138],\n",
       "       [0.0528025 , 0.94719744],\n",
       "       [0.33827186, 0.6617281 ],\n",
       "       [0.978231  , 0.021769  ],\n",
       "       [0.03115033, 0.9688496 ],\n",
       "       [0.77362835, 0.22637159],\n",
       "       [0.02230924, 0.97769076],\n",
       "       [0.07809337, 0.9219066 ],\n",
       "       [0.9791709 , 0.02082916],\n",
       "       [0.9791709 , 0.02082916],\n",
       "       [0.9401724 , 0.05982767],\n",
       "       [0.8983361 , 0.10166382],\n",
       "       [0.21344028, 0.7865597 ],\n",
       "       [0.03556701, 0.96443295],\n",
       "       [0.9779537 , 0.02204627],\n",
       "       [0.01950561, 0.9804944 ],\n",
       "       [0.03556701, 0.96443295],\n",
       "       [0.9623559 , 0.03764416],\n",
       "       [0.95266944, 0.04733051],\n",
       "       [0.01950561, 0.9804944 ],\n",
       "       [0.92264813, 0.07735185],\n",
       "       [0.9786405 , 0.02135949],\n",
       "       [0.04334794, 0.95665205],\n",
       "       [0.02550539, 0.9744946 ],\n",
       "       [0.97411966, 0.02588041],\n",
       "       [0.02086139, 0.9791387 ],\n",
       "       [0.03115033, 0.9688496 ],\n",
       "       [0.97704244, 0.02295759],\n",
       "       [0.12590982, 0.8740902 ],\n",
       "       [0.06845681, 0.9315432 ],\n",
       "       [0.9401724 , 0.05982767],\n",
       "       [0.8983361 , 0.10166382],\n",
       "       [0.97704244, 0.02295759],\n",
       "       [0.27137482, 0.7286252 ],\n",
       "       [0.03556701, 0.96443295],\n",
       "       [0.80015135, 0.19984868],\n",
       "       [0.21344028, 0.7865597 ],\n",
       "       [0.979301  , 0.02069897],\n",
       "       [0.16507185, 0.8349281 ],\n",
       "       [0.45114982, 0.5488501 ],\n",
       "       [0.8460425 , 0.15395743],\n",
       "       [0.9401724 , 0.05982767],\n",
       "       [0.9786405 , 0.02135949],\n",
       "       [0.607611  , 0.392389  ],\n",
       "       [0.80015135, 0.19984868],\n",
       "       [0.9787754 , 0.02122467],\n",
       "       [0.03115033, 0.9688496 ],\n",
       "       [0.8460425 , 0.15395743],\n",
       "       [0.9779537 , 0.02204627],\n",
       "       [0.03556701, 0.96443295],\n",
       "       [0.979301  , 0.02069897],\n",
       "       [0.0528025 , 0.94719744],\n",
       "       [0.9793452 , 0.02065476],\n",
       "       [0.06845681, 0.9315432 ],\n",
       "       [0.0528025 , 0.94719744],\n",
       "       [0.04945248, 0.9505476 ],\n",
       "       [0.12590982, 0.8740902 ],\n",
       "       [0.9798139 , 0.02018613],\n",
       "       [0.8829375 , 0.11706249],\n",
       "       [0.12590982, 0.8740902 ],\n",
       "       [0.97903985, 0.02096015],\n",
       "       [0.9791709 , 0.02082916],\n",
       "       [0.6446507 , 0.3553493 ],\n",
       "       [0.03799591, 0.96200407],\n",
       "       [0.01950561, 0.9804944 ],\n",
       "       [0.10949168, 0.8905083 ],\n",
       "       [0.9780928 , 0.02190721],\n",
       "       [0.9779537 , 0.02204627],\n",
       "       [0.14439069, 0.85560924],\n",
       "       [0.0950925 , 0.90490746],\n",
       "       [0.10949168, 0.8905083 ],\n",
       "       [0.12590982, 0.8740902 ],\n",
       "       [0.12590982, 0.8740902 ],\n",
       "       [0.6800353 , 0.31996468],\n",
       "       [0.6446507 , 0.3553493 ],\n",
       "       [0.03799591, 0.96200407],\n",
       "       [0.07809337, 0.9219066 ],\n",
       "       [0.0528025 , 0.94719744],\n",
       "       [0.02230924, 0.97769076],\n",
       "       [0.03799591, 0.96200407],\n",
       "       [0.27137482, 0.7286252 ],\n",
       "       [0.9623559 , 0.03764416],\n",
       "       [0.01950561, 0.9804944 ],\n",
       "       [0.9786078 , 0.02139219],\n",
       "       [0.9401724 , 0.05982767],\n",
       "       [0.08427152, 0.9157285 ],\n",
       "       [0.06845681, 0.9315432 ],\n",
       "       [0.03328802, 0.96671194],\n",
       "       [0.77362835, 0.22637159],\n",
       "       [0.9785049 , 0.02149515],\n",
       "       [0.9785049 , 0.02149515],\n",
       "       [0.9798139 , 0.02018613],\n",
       "       [0.9578345 , 0.04216551],\n",
       "       [0.97411966, 0.02588041],\n",
       "       [0.97987455, 0.02012547],\n",
       "       [0.9752703 , 0.02472966],\n",
       "       [0.97208965, 0.02791027],\n",
       "       [0.07299537, 0.9270047 ],\n",
       "       [0.06418084, 0.93581915],\n",
       "       [0.03799591, 0.96200407],\n",
       "       [0.02086139, 0.9791387 ],\n",
       "       [0.03556701, 0.96443295],\n",
       "       [0.33827186, 0.6617281 ],\n",
       "       [0.04945248, 0.9505476 ],\n",
       "       [0.6446507 , 0.3553493 ],\n",
       "       [0.03115033, 0.9688496 ],\n",
       "       [0.9401724 , 0.05982767],\n",
       "       [0.97411966, 0.02588041],\n",
       "       [0.97903985, 0.02096015],\n",
       "       [0.0272666 , 0.97273344],\n",
       "       [0.04334794, 0.95665205],\n",
       "       [0.9623559 , 0.03764416],\n",
       "       [0.9401724 , 0.05982767],\n",
       "       [0.0601548 , 0.9398452 ],\n",
       "       [0.97903985, 0.02096015],\n",
       "       [0.9791709 , 0.02082916],\n",
       "       [0.9623559 , 0.03764416],\n",
       "       [0.03115033, 0.9688496 ],\n",
       "       [0.16507185, 0.8349281 ],\n",
       "       [0.07809337, 0.9219066 ],\n",
       "       [0.97411966, 0.02588041],\n",
       "       [0.979864  , 0.02013604],\n",
       "       [0.45114982, 0.5488501 ],\n",
       "       [0.9786078 , 0.02139219],\n",
       "       [0.24122326, 0.7587768 ],\n",
       "       [0.07299537, 0.9270047 ],\n",
       "       [0.3745658 , 0.62543416],\n",
       "       [0.04334794, 0.95665205],\n",
       "       [0.5301204 , 0.46987966],\n",
       "       [0.03115033, 0.9688496 ],\n",
       "       [0.30378637, 0.6962136 ],\n",
       "       [0.8829375 , 0.11706249],\n",
       "       [0.8983361 , 0.10166382],\n",
       "       [0.979301  , 0.02069897],\n",
       "       [0.9785049 , 0.02149515],\n",
       "       [0.02550539, 0.9744946 ],\n",
       "       [0.33827186, 0.6617281 ],\n",
       "       [0.9798139 , 0.02018613],\n",
       "       [0.08427152, 0.9157285 ],\n",
       "       [0.03799591, 0.96200407],\n",
       "       [0.9752703 , 0.02472966],\n",
       "       [0.18806422, 0.8119358 ],\n",
       "       [0.02086139, 0.9791387 ],\n",
       "       [0.97704244, 0.02295759],\n",
       "       [0.9796438 , 0.0203561 ],\n",
       "       [0.06845681, 0.9315432 ],\n",
       "       [0.97987455, 0.02012547],\n",
       "       [0.16507185, 0.8349281 ],\n",
       "       [0.12590982, 0.8740902 ],\n",
       "       [0.04334794, 0.95665205],\n",
       "       [0.05636603, 0.943634  ],\n",
       "       [0.5301204 , 0.46987966],\n",
       "       [0.07299537, 0.9270047 ],\n",
       "       [0.03328802, 0.96671194],\n",
       "       [0.03799591, 0.96200407],\n",
       "       [0.02086139, 0.9791387 ],\n",
       "       [0.9578345 , 0.04216551],\n",
       "       [0.97783864, 0.02216138],\n",
       "       [0.97987455, 0.02012547],\n",
       "       [0.0272666 , 0.97273344],\n",
       "       [0.03115033, 0.9688496 ],\n",
       "       [0.9798139 , 0.02018613],\n",
       "       [0.02550539, 0.9744946 ],\n",
       "       [0.04630458, 0.9536955 ],\n",
       "       [0.979864  , 0.02013604],\n",
       "       [0.8829375 , 0.11706249],\n",
       "       [0.02914577, 0.9708543 ],\n",
       "       [0.77362835, 0.22637159],\n",
       "       [0.0272666 , 0.97273344],\n",
       "       [0.10949168, 0.8905083 ],\n",
       "       [0.45114982, 0.5488501 ],\n",
       "       [0.74470854, 0.2552914 ],\n",
       "       [0.97903985, 0.02096015],\n",
       "       [0.9786078 , 0.02139219],\n",
       "       [0.9401724 , 0.05982767],\n",
       "       [0.24122326, 0.7587768 ],\n",
       "       [0.9787754 , 0.02122467],\n",
       "       [0.18806422, 0.8119358 ],\n",
       "       [0.02550539, 0.9744946 ],\n",
       "       [0.04630458, 0.9536955 ],\n",
       "       [0.5692898 , 0.43071017],\n",
       "       [0.02385515, 0.97614485],\n",
       "       [0.97890806, 0.02109195],\n",
       "       [0.03115033, 0.9688496 ],\n",
       "       [0.04945248, 0.9505476 ],\n",
       "       [0.21344028, 0.7865597 ],\n",
       "       [0.45114982, 0.5488501 ],\n",
       "       [0.27137482, 0.7286252 ],\n",
       "       [0.97903985, 0.02096015],\n",
       "       [0.08427152, 0.9157285 ],\n",
       "       [0.0528025 , 0.94719744],\n",
       "       [0.04334794, 0.95665205],\n",
       "       [0.08427152, 0.9157285 ],\n",
       "       [0.33827186, 0.6617281 ],\n",
       "       [0.77362835, 0.22637159],\n",
       "       [0.5692898 , 0.43071017],\n",
       "       [0.16507185, 0.8349281 ],\n",
       "       [0.3745658 , 0.62543416],\n",
       "       [0.03799591, 0.96200407],\n",
       "       [0.05636603, 0.943634  ],\n",
       "       [0.02550539, 0.9744946 ],\n",
       "       [0.0528025 , 0.94719744],\n",
       "       [0.9663431 , 0.0336569 ],\n",
       "       [0.607611  , 0.392389  ],\n",
       "       [0.74470854, 0.2552914 ],\n",
       "       [0.9779537 , 0.02204627],\n",
       "       [0.03556701, 0.96443295],\n",
       "       [0.01950561, 0.9804944 ],\n",
       "       [0.9796438 , 0.0203561 ],\n",
       "       [0.97783864, 0.02216138],\n",
       "       [0.04058368, 0.95941633],\n",
       "       [0.97783864, 0.02216138],\n",
       "       [0.16507185, 0.8349281 ],\n",
       "       [0.8829375 , 0.11706249],\n",
       "       [0.9786405 , 0.02135949],\n",
       "       [0.9786078 , 0.02139219],\n",
       "       [0.8460425 , 0.15395743],\n",
       "       [0.05636603, 0.943634  ],\n",
       "       [0.97943044, 0.02056957],\n",
       "       [0.03115033, 0.9688496 ],\n",
       "       [0.97968686, 0.02031316],\n",
       "       [0.86555547, 0.13444452],\n",
       "       [0.08427152, 0.9157285 ],\n",
       "       [0.0272666 , 0.97273344],\n",
       "       [0.27137482, 0.7286252 ],\n",
       "       [0.03328802, 0.96671194],\n",
       "       [0.33827186, 0.6617281 ],\n",
       "       [0.03115033, 0.9688496 ],\n",
       "       [0.10949168, 0.8905083 ],\n",
       "       [0.0950925 , 0.90490746],\n",
       "       [0.02385515, 0.97614485],\n",
       "       [0.03799591, 0.96200407],\n",
       "       [0.80015135, 0.19984868],\n",
       "       [0.9752703 , 0.02472966],\n",
       "       [0.04058368, 0.95941633],\n",
       "       [0.97208965, 0.02791027],\n",
       "       [0.06418084, 0.93581915],\n",
       "       [0.9779537 , 0.02204627],\n",
       "       [0.0601548 , 0.9398452 ],\n",
       "       [0.97943044, 0.02056957],\n",
       "       [0.9578345 , 0.04216551],\n",
       "       [0.24122326, 0.7587768 ],\n",
       "       [0.21344028, 0.7865597 ],\n",
       "       [0.0601548 , 0.9398452 ],\n",
       "       [0.24122326, 0.7587768 ],\n",
       "       [0.45114982, 0.5488501 ],\n",
       "       [0.3745658 , 0.62543416],\n",
       "       [0.97704244, 0.02295759],\n",
       "       [0.03115033, 0.9688496 ],\n",
       "       [0.30378637, 0.6962136 ],\n",
       "       [0.9401724 , 0.05982767],\n",
       "       [0.0528025 , 0.94719744],\n",
       "       [0.97890806, 0.02109195],\n",
       "       [0.9779537 , 0.02204627],\n",
       "       [0.96959955, 0.03040039],\n",
       "       [0.04630458, 0.9536955 ],\n",
       "       [0.9578345 , 0.04216551],\n",
       "       [0.02086139, 0.9791387 ],\n",
       "       [0.03328802, 0.96671194],\n",
       "       [0.92264813, 0.07735185],\n",
       "       [0.9578345 , 0.04216551],\n",
       "       [0.08427152, 0.9157285 ],\n",
       "       [0.06418084, 0.93581915],\n",
       "       [0.0601548 , 0.9398452 ],\n",
       "       [0.02086139, 0.9791387 ],\n",
       "       [0.946766  , 0.05323403],\n",
       "       [0.07809337, 0.9219066 ],\n",
       "       [0.946766  , 0.05323403],\n",
       "       [0.02914577, 0.9708543 ],\n",
       "       [0.97890806, 0.02109195],\n",
       "       [0.978231  , 0.021769  ],\n",
       "       [0.97890806, 0.02109195],\n",
       "       [0.02914577, 0.9708543 ],\n",
       "       [0.9796438 , 0.0203561 ],\n",
       "       [0.97968686, 0.02031316],\n",
       "       [0.80015135, 0.19984868],\n",
       "       [0.97890806, 0.02109195],\n",
       "       [0.02230924, 0.97769076],\n",
       "       [0.0950925 , 0.90490746],\n",
       "       [0.9780928 , 0.02190721],\n",
       "       [0.10949168, 0.8905083 ],\n",
       "       [0.9578345 , 0.04216551],\n",
       "       [0.0601548 , 0.9398452 ],\n",
       "       [0.07299537, 0.9270047 ],\n",
       "       [0.14439069, 0.85560924],\n",
       "       [0.03556701, 0.96443295],\n",
       "       [0.5301204 , 0.46987966],\n",
       "       [0.24122326, 0.7587768 ],\n",
       "       [0.95266944, 0.04733051],\n",
       "       [0.0272666 , 0.97273344],\n",
       "       [0.9791709 , 0.02082916],\n",
       "       [0.02385515, 0.97614485],\n",
       "       [0.9779537 , 0.02204627],\n",
       "       [0.946766  , 0.05323403],\n",
       "       [0.9401724 , 0.05982767],\n",
       "       [0.06418084, 0.93581915],\n",
       "       [0.9786405 , 0.02135949],\n",
       "       [0.02230924, 0.97769076],\n",
       "       [0.979864  , 0.02013604],\n",
       "       [0.74470854, 0.2552914 ],\n",
       "       [0.9796438 , 0.0203561 ],\n",
       "       [0.21344028, 0.7865597 ],\n",
       "       [0.30378637, 0.6962136 ],\n",
       "       [0.27137482, 0.7286252 ],\n",
       "       [0.02914577, 0.9708543 ],\n",
       "       [0.33827186, 0.6617281 ],\n",
       "       [0.9785049 , 0.02149515],\n",
       "       [0.9401724 , 0.05982767],\n",
       "       [0.97955894, 0.02044098],\n",
       "       [0.979864  , 0.02013604],\n",
       "       [0.9783683 , 0.02163165],\n",
       "       [0.04630458, 0.9536955 ],\n",
       "       [0.9783683 , 0.02163165],\n",
       "       [0.16507185, 0.8349281 ],\n",
       "       [0.07299537, 0.9270047 ],\n",
       "       [0.02914577, 0.9708543 ],\n",
       "       [0.05636603, 0.943634  ],\n",
       "       [0.03328802, 0.96671194],\n",
       "       [0.9786078 , 0.02139219],\n",
       "       [0.9785049 , 0.02149515],\n",
       "       [0.95266944, 0.04733051],\n",
       "       [0.0528025 , 0.94719744],\n",
       "       [0.9791709 , 0.02082916],\n",
       "       [0.7134625 , 0.28653756],\n",
       "       [0.41232753, 0.58767253],\n",
       "       [0.979864  , 0.02013604],\n",
       "       [0.97903985, 0.02096015],\n",
       "       [0.97903985, 0.02096015],\n",
       "       [0.97411966, 0.02588041],\n",
       "       [0.05636603, 0.943634  ],\n",
       "       [0.01950561, 0.9804944 ],\n",
       "       [0.0950925 , 0.90490746],\n",
       "       [0.30378637, 0.6962136 ],\n",
       "       [0.97903985, 0.02096015],\n",
       "       [0.14439069, 0.85560924],\n",
       "       [0.03328802, 0.96671194],\n",
       "       [0.41232753, 0.58767253],\n",
       "       [0.97704244, 0.02295759],\n",
       "       [0.12590982, 0.8740902 ],\n",
       "       [0.03328802, 0.96671194],\n",
       "       [0.95266944, 0.04733051],\n",
       "       [0.979864  , 0.02013604],\n",
       "       [0.9779537 , 0.02204627],\n",
       "       [0.9786078 , 0.02139219],\n",
       "       [0.6800353 , 0.31996468],\n",
       "       [0.01950561, 0.9804944 ],\n",
       "       [0.05636603, 0.943634  ],\n",
       "       [0.04630458, 0.9536955 ],\n",
       "       [0.01950561, 0.9804944 ],\n",
       "       [0.9783683 , 0.02163165],\n",
       "       [0.9324081 , 0.06759194],\n",
       "       [0.9785049 , 0.02149515],\n",
       "       [0.03556701, 0.96443295],\n",
       "       [0.02550539, 0.9744946 ],\n",
       "       [0.45114982, 0.5488501 ],\n",
       "       [0.05636603, 0.943634  ],\n",
       "       [0.9786078 , 0.02139219],\n",
       "       [0.8983361 , 0.10166382],\n",
       "       [0.77362835, 0.22637159],\n",
       "       [0.03799591, 0.96200407],\n",
       "       [0.04058368, 0.95941633],\n",
       "       [0.97968686, 0.02031316],\n",
       "       [0.9401724 , 0.05982767],\n",
       "       [0.86555547, 0.13444452],\n",
       "       [0.01950561, 0.9804944 ],\n",
       "       [0.978231  , 0.021769  ],\n",
       "       [0.45114982, 0.5488501 ],\n",
       "       [0.97621834, 0.02378169],\n",
       "       [0.97955894, 0.02044098],\n",
       "       [0.9791709 , 0.02082916],\n",
       "       [0.02550539, 0.9744946 ],\n",
       "       [0.80015135, 0.19984868],\n",
       "       [0.33827186, 0.6617281 ],\n",
       "       [0.96959955, 0.03040039],\n",
       "       [0.8829375 , 0.11706249],\n",
       "       [0.02550539, 0.9744946 ],\n",
       "       [0.0272666 , 0.97273344],\n",
       "       [0.97704244, 0.02295759],\n",
       "       [0.946766  , 0.05323403],\n",
       "       [0.03328802, 0.96671194],\n",
       "       [0.18806422, 0.8119358 ],\n",
       "       [0.9663431 , 0.0336569 ],\n",
       "       [0.04945248, 0.9505476 ],\n",
       "       [0.9401724 , 0.05982767],\n",
       "       [0.9783683 , 0.02163165],\n",
       "       [0.08427152, 0.9157285 ],\n",
       "       [0.97208965, 0.02791027],\n",
       "       [0.9793452 , 0.02065476],\n",
       "       [0.02230924, 0.97769076],\n",
       "       [0.33827186, 0.6617281 ],\n",
       "       [0.02550539, 0.9744946 ],\n",
       "       [0.02385515, 0.97614485],\n",
       "       [0.27137482, 0.7286252 ],\n",
       "       [0.04334794, 0.95665205],\n",
       "       [0.9663431 , 0.0336569 ],\n",
       "       [0.04058368, 0.95941633],\n",
       "       [0.9798139 , 0.02018613],\n",
       "       [0.8242725 , 0.17572746],\n",
       "       [0.9793452 , 0.02065476],\n",
       "       [0.74470854, 0.2552914 ],\n",
       "       [0.97704244, 0.02295759],\n",
       "       [0.9787754 , 0.02122467],\n",
       "       [0.9663431 , 0.0336569 ],\n",
       "       [0.16507185, 0.8349281 ],\n",
       "       [0.9798139 , 0.02018613],\n",
       "       [0.06845681, 0.9315432 ],\n",
       "       [0.97903985, 0.02096015],\n",
       "       [0.05636603, 0.943634  ],\n",
       "       [0.45114982, 0.5488501 ],\n",
       "       [0.9115055 , 0.08849451],\n",
       "       [0.07299537, 0.9270047 ],\n",
       "       [0.9785049 , 0.02149515],\n",
       "       [0.3745658 , 0.62543416]], dtype=float32)"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_model.predict(x=scaled_test_samples, batch_size = 10, verbose=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "proud-curtis",
   "metadata": {},
   "outputs": [],
   "source": [
    "json_string = model.to_json()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "saving-stewart",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'{\"class_name\": \"Sequential\", \"config\": {\"name\": \"sequential_4\", \"layers\": [{\"class_name\": \"InputLayer\", \"config\": {\"batch_input_shape\": [null, 1], \"dtype\": \"float32\", \"sparse\": false, \"ragged\": false, \"name\": \"dense_12_input\"}}, {\"class_name\": \"Dense\", \"config\": {\"name\": \"dense_12\", \"trainable\": true, \"batch_input_shape\": [null, 1], \"dtype\": \"float32\", \"units\": 16, \"activation\": \"relu\", \"use_bias\": true, \"kernel_initializer\": {\"class_name\": \"GlorotUniform\", \"config\": {\"seed\": null}}, \"bias_initializer\": {\"class_name\": \"Zeros\", \"config\": {}}, \"kernel_regularizer\": null, \"bias_regularizer\": null, \"activity_regularizer\": null, \"kernel_constraint\": null, \"bias_constraint\": null}}, {\"class_name\": \"Dense\", \"config\": {\"name\": \"dense_13\", \"trainable\": true, \"dtype\": \"float32\", \"units\": 32, \"activation\": \"relu\", \"use_bias\": true, \"kernel_initializer\": {\"class_name\": \"GlorotUniform\", \"config\": {\"seed\": null}}, \"bias_initializer\": {\"class_name\": \"Zeros\", \"config\": {}}, \"kernel_regularizer\": null, \"bias_regularizer\": null, \"activity_regularizer\": null, \"kernel_constraint\": null, \"bias_constraint\": null}}, {\"class_name\": \"Dense\", \"config\": {\"name\": \"dense_14\", \"trainable\": true, \"dtype\": \"float32\", \"units\": 2, \"activation\": \"softmax\", \"use_bias\": true, \"kernel_initializer\": {\"class_name\": \"GlorotUniform\", \"config\": {\"seed\": null}}, \"bias_initializer\": {\"class_name\": \"Zeros\", \"config\": {}}, \"kernel_regularizer\": null, \"bias_regularizer\": null, \"activity_regularizer\": null, \"kernel_constraint\": null, \"bias_constraint\": null}}]}, \"keras_version\": \"2.5.0\", \"backend\": \"tensorflow\"}'"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "json_string"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "gross-antique",
   "metadata": {},
   "outputs": [],
   "source": [
    "# can get model back from json string using model_from_json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "welsh-composition",
   "metadata": {},
   "outputs": [],
   "source": [
    "# if you only have the weights saved then define another model let us suppose model2 with same architecture and load_weights\n",
    "# using the file loaction into the model2."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
